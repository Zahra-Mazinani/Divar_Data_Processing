{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Zahra-Mazinani/Data_Divar/blob/main/DivarFeatureDetection.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "g7nBInE4cWhe"
      },
      "source": [
        "# In the name of Allah\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "IHD0hJbsco_p",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "f95bb36b-2bad-4df4-e5de-882584651da2"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Collecting pyspark\n",
            "  Downloading pyspark-3.3.0.tar.gz (281.3 MB)\n",
            "\u001b[K     |████████████████████████████████| 281.3 MB 64 kB/s \n",
            "\u001b[?25hCollecting py4j==0.10.9.5\n",
            "  Downloading py4j-0.10.9.5-py2.py3-none-any.whl (199 kB)\n",
            "\u001b[K     |████████████████████████████████| 199 kB 83.6 MB/s \n",
            "\u001b[?25hBuilding wheels for collected packages: pyspark\n",
            "  Building wheel for pyspark (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for pyspark: filename=pyspark-3.3.0-py2.py3-none-any.whl size=281764026 sha256=af7211b38a600b4671a0bfd66a5fac224e56dc2edc5e2902e17db4353b6a8dcf\n",
            "  Stored in directory: /root/.cache/pip/wheels/7a/8e/1b/f73a52650d2e5f337708d9f6a1750d451a7349a867f928b885\n",
            "Successfully built pyspark\n",
            "Installing collected packages: py4j, pyspark\n",
            "Successfully installed py4j-0.10.9.5 pyspark-3.3.0\n",
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Collecting parsivar\n",
            "  Downloading parsivar-0.2.3.tar.gz (36.2 MB)\n",
            "\u001b[K     |████████████████████████████████| 36.2 MB 1.2 MB/s \n",
            "\u001b[?25hCollecting nltk==3.4.5\n",
            "  Downloading nltk-3.4.5.zip (1.5 MB)\n",
            "\u001b[K     |████████████████████████████████| 1.5 MB 62.2 MB/s \n",
            "\u001b[?25hRequirement already satisfied: six in /usr/local/lib/python3.7/dist-packages (from nltk==3.4.5->parsivar) (1.15.0)\n",
            "Building wheels for collected packages: parsivar, nltk\n",
            "  Building wheel for parsivar (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for parsivar: filename=parsivar-0.2.3-py3-none-any.whl size=36492972 sha256=21673b0d01db5fccb463647b6411c86b1f269fea63c829d9f4fb4bc699f25496\n",
            "  Stored in directory: /root/.cache/pip/wheels/ae/67/7a/49cbf08f64d3f76a26eceaf0e481a40e233f05d4356875cbed\n",
            "  Building wheel for nltk (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for nltk: filename=nltk-3.4.5-py3-none-any.whl size=1449921 sha256=b9698fa58dc79ef98b713ececd8aa15684a0f91e9e0a51530dff57819ce5d4e5\n",
            "  Stored in directory: /root/.cache/pip/wheels/48/8b/7f/473521e0c731c6566d631b281f323842bbda9bd819eb9a3ead\n",
            "Successfully built parsivar nltk\n",
            "Installing collected packages: nltk, parsivar\n",
            "  Attempting uninstall: nltk\n",
            "    Found existing installation: nltk 3.7\n",
            "    Uninstalling nltk-3.7:\n",
            "      Successfully uninstalled nltk-3.7\n",
            "Successfully installed nltk-3.4.5 parsivar-0.2.3\n",
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Collecting catboost\n",
            "  Downloading catboost-1.0.6-cp37-none-manylinux1_x86_64.whl (76.6 MB)\n",
            "\u001b[K     |████████████████████████████████| 76.6 MB 203 kB/s \n",
            "\u001b[?25hCollecting shap\n",
            "  Downloading shap-0.41.0-cp37-cp37m-manylinux_2_12_x86_64.manylinux2010_x86_64.whl (569 kB)\n",
            "\u001b[K     |████████████████████████████████| 569 kB 64.6 MB/s \n",
            "\u001b[?25hRequirement already satisfied: scipy in /usr/local/lib/python3.7/dist-packages (from catboost) (1.7.3)\n",
            "Requirement already satisfied: graphviz in /usr/local/lib/python3.7/dist-packages (from catboost) (0.10.1)\n",
            "Requirement already satisfied: numpy>=1.16.0 in /usr/local/lib/python3.7/dist-packages (from catboost) (1.21.6)\n",
            "Requirement already satisfied: matplotlib in /usr/local/lib/python3.7/dist-packages (from catboost) (3.2.2)\n",
            "Requirement already satisfied: plotly in /usr/local/lib/python3.7/dist-packages (from catboost) (5.5.0)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.7/dist-packages (from catboost) (1.15.0)\n",
            "Requirement already satisfied: pandas>=0.24.0 in /usr/local/lib/python3.7/dist-packages (from catboost) (1.3.5)\n",
            "Requirement already satisfied: pytz>=2017.3 in /usr/local/lib/python3.7/dist-packages (from pandas>=0.24.0->catboost) (2022.1)\n",
            "Requirement already satisfied: python-dateutil>=2.7.3 in /usr/local/lib/python3.7/dist-packages (from pandas>=0.24.0->catboost) (2.8.2)\n",
            "Requirement already satisfied: tqdm>4.25.0 in /usr/local/lib/python3.7/dist-packages (from shap) (4.64.0)\n",
            "Requirement already satisfied: cloudpickle in /usr/local/lib/python3.7/dist-packages (from shap) (1.3.0)\n",
            "Collecting slicer==0.0.7\n",
            "  Downloading slicer-0.0.7-py3-none-any.whl (14 kB)\n",
            "Requirement already satisfied: numba in /usr/local/lib/python3.7/dist-packages (from shap) (0.56.0)\n",
            "Requirement already satisfied: scikit-learn in /usr/local/lib/python3.7/dist-packages (from shap) (1.0.2)\n",
            "Requirement already satisfied: packaging>20.9 in /usr/local/lib/python3.7/dist-packages (from shap) (21.3)\n",
            "Requirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /usr/local/lib/python3.7/dist-packages (from packaging>20.9->shap) (3.0.9)\n",
            "Requirement already satisfied: kiwisolver>=1.0.1 in /usr/local/lib/python3.7/dist-packages (from matplotlib->catboost) (1.4.4)\n",
            "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.7/dist-packages (from matplotlib->catboost) (0.11.0)\n",
            "Requirement already satisfied: typing-extensions in /usr/local/lib/python3.7/dist-packages (from kiwisolver>=1.0.1->matplotlib->catboost) (4.1.1)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.7/dist-packages (from numba->shap) (57.4.0)\n",
            "Requirement already satisfied: llvmlite<0.40,>=0.39.0dev0 in /usr/local/lib/python3.7/dist-packages (from numba->shap) (0.39.0)\n",
            "Requirement already satisfied: importlib-metadata in /usr/local/lib/python3.7/dist-packages (from numba->shap) (4.12.0)\n",
            "Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.7/dist-packages (from importlib-metadata->numba->shap) (3.8.1)\n",
            "Requirement already satisfied: tenacity>=6.2.0 in /usr/local/lib/python3.7/dist-packages (from plotly->catboost) (8.0.1)\n",
            "Requirement already satisfied: joblib>=0.11 in /usr/local/lib/python3.7/dist-packages (from scikit-learn->shap) (1.1.0)\n",
            "Requirement already satisfied: threadpoolctl>=2.0.0 in /usr/local/lib/python3.7/dist-packages (from scikit-learn->shap) (3.1.0)\n",
            "Installing collected packages: slicer, shap, catboost\n",
            "Successfully installed catboost-1.0.6 shap-0.41.0 slicer-0.0.7\n"
          ]
        }
      ],
      "source": [
        "!pip install pyspark\n",
        "!pip install parsivar\n",
        "!pip install catboost shap "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "4pBF6hXVcfwv",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "5a8759a6-c15f-4746-b7b6-1947b2b9ba05"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n",
            "Archive:  /content/drive/MyDrive/Colab Notebooks/Divar/DMC-phase1-DataSets-20211225T055615Z-001.zip\n",
            "  inflating: DMC-phase1-DataSets/reject_reasons_info.csv  \n",
            "  inflating: DMC-phase1-DataSets/DMC-Phase1-Validation.parquet  \n",
            "  inflating: DMC-phase1-DataSets/DMC-Train.parquet  \n"
          ]
        }
      ],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')\n",
        "!unzip \"/content/drive/MyDrive/Colab Notebooks/Divar/DMC-phase1-DataSets-20211225T055615Z-001.zip\" "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "CAyRgn2tcLIp"
      },
      "outputs": [],
      "source": [
        "from pyspark.sql import SparkSession\n",
        "from pyspark.sql.functions import *\n",
        "from pyspark.sql.types import *\n",
        "from pyspark.ml.feature import *\n",
        "\n",
        "import pandas as pd\n",
        "import numpy as np"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "VafQsJ0McoSN"
      },
      "outputs": [],
      "source": [
        "path = \"/content/DMC-phase1-DataSets\"\n",
        "\n",
        "spark = SparkSession.builder.appName('Divar').getOrCreate()\n",
        "\n",
        "df_train = spark.read.parquet(path + '/DMC-Train.parquet')\n",
        "df_test = spark.read.parquet(path + '/DMC-Phase1-Validation.parquet')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "KPF7zyJ_xjEC"
      },
      "outputs": [],
      "source": [
        "schema = StructType([ \n",
        "    StructField(\"body_status\",StringType(),True), \n",
        "    StructField(\"brand\",StringType(),True), \n",
        "    StructField(\"brand_model\",StringType(),True), \n",
        "    StructField(\"category\",StringType(),True), \n",
        "    StructField(\"color\",StringType(),True), \n",
        "    StructField(\"description\",StringType(),True), \n",
        "    StructField(\"document\",StringType(),True), \n",
        "    StructField(\"gearbox\",StringType(),True), \n",
        "    StructField(\"new_price\",IntegerType(),True), \n",
        "    StructField(\"post_type\",StringType(),True), \n",
        "    StructField(\"selling_type\",StringType(),True), \n",
        "    StructField(\"third_party_insurance_deadline\",IntegerType(),True), \n",
        "    StructField(\"tit le\",StringType(),True), \n",
        "    StructField(\"usage\", IntegerType(), True),\n",
        "    StructField(\"year\", StringType(), True)\n",
        "  ])\n",
        "\n",
        "df_train = df_train.withColumn(\"post_data\", from_json(\"post_data\", schema))\\\n",
        "    .select(col('post_id'),\n",
        "            col('review_label'),\n",
        "            col('post_data.*'))\n",
        "df_test = df_test.withColumn(\"post_data\", from_json(\"post_data\", schema))\\\n",
        "    .select(col('post_id'),\n",
        "            col('post_data.*'))\n",
        "\n",
        "df_train = df_train.withColumn(\"review_label\", when(df_train.review_label == \"accept\",\"1\")\\\n",
        "      .when(df_train.review_label == \"reject\",\"0\"))\n",
        "df_train = df_train.withColumn(\"review_label\",col(\"review_label\").cast(IntegerType()))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "w4Jeoy1eh4DG"
      },
      "source": [
        "## Preproccecing"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "EOc_utCkjSiq"
      },
      "source": [
        "### Utils"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "PB8jffpNZyrb"
      },
      "outputs": [],
      "source": [
        "from __future__ import unicode_literals\n",
        "\n",
        "import collections\n",
        "import gc      #garbage\n",
        "import json\n",
        "import re\n",
        "import os\n",
        "\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import parsivar\n",
        "from sklearn.feature_extraction.text import TfidfVectorizer\n",
        "from tqdm import tqdm"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "3NV5nVphiuol"
      },
      "outputs": [],
      "source": [
        "def read_json(path, n_lines_to_read=None):\n",
        "    \"\"\"\n",
        "    read json file line by line iteratively (generator function).\n",
        "    use this function to read json files when you have memory limitations.\n",
        "    \"\"\"\n",
        "\n",
        "    with open(path) as f:\n",
        "        for i, line in enumerate(tqdm(f)):\n",
        "            if n_lines_to_read == i:\n",
        "                break\n",
        "            yield json.loads(line)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "IJaXJnDkK6dR"
      },
      "outputs": [],
      "source": [
        "parsivar_normalizer = parsivar.Normalizer(statistical_space_correction=True)\n",
        "\n",
        "char_mappings = {\n",
        "    \"٥\": \"5\",\n",
        "    \"А\": \"a\",\n",
        "    \"В\": \"b\",\n",
        "    \"Е\": \"e\",\n",
        "    \"Н\": \"h\",\n",
        "    \"Р\": \"P\",\n",
        "    \"С\": \"C\",\n",
        "    \"Т\": \"T\",\n",
        "    \"а\": \"a\",\n",
        "    \"г\": \"r\",\n",
        "    \"е\": \"e\",\n",
        "    \"к\": \"k\",\n",
        "    \"м\": \"m\",\n",
        "    \"о\": \"o\",\n",
        "    \"р\": \"p\",\n",
        "    \"ڈ\": \"د\",\n",
        "    \"ڇ\": \"چ\",\n",
        "    # Persian numbers (will be raplaced by english one)\n",
        "    \"۰\": \"0\",\n",
        "    \"۱\": \"1\",\n",
        "    \"۲\": \"2\",\n",
        "    \"۳\": \"3\",\n",
        "    \"۴\": \"4\",\n",
        "    \"۵\": \"5\",\n",
        "    \"۶\": \"6\",\n",
        "    \"۷\": \"7\",\n",
        "    \"۸\": \"8\",\n",
        "    \"۹\": \"9\",\n",
        "    \".\": \".\",\n",
        "    # Arabic numbers (will be raplaced by english one)\n",
        "    \"٠\": \"0\",\n",
        "    \"١\": \"1\",\n",
        "    \"٢\": \"2\",\n",
        "    \"٣\": \"3\",\n",
        "    \"٤\": \"4\",\n",
        "    \"٥\": \"5\",\n",
        "    \"٦\": \"6\",\n",
        "    \"٧\": \"7\",\n",
        "    \"٨\": \"8\",\n",
        "    \"٩\": \"9\",\n",
        "    # Special Arabic Characters (will be replaced by persian one)\n",
        "    \"ك\": \"ک\",\n",
        "    \"ى\": \"ی\",\n",
        "    \"ي\": \"ی\",\n",
        "    \"ؤ\": \"و\",\n",
        "    \"ئ\": \"ی\",\n",
        "    \"إ\": \"ا\",\n",
        "    \"أ\": \"ا\",\n",
        "    \"آ\": \"ا\",\n",
        "    \"ة\": \"ه\",\n",
        "    \"ء\": \"ی\",\n",
        "    # French alphabet (will be raplaced by english one)\n",
        "    \"à\": \"a\",\n",
        "    \"ä\": \"a\",\n",
        "    \"ç\": \"c\",\n",
        "    \"é\": \"e\",\n",
        "    \"è\": \"e\",\n",
        "    \"ê\": \"e\",\n",
        "    \"ë\": \"e\",\n",
        "    \"î\": \"i\",\n",
        "    \"ï\": \"i\",\n",
        "    \"ô\": \"o\",\n",
        "    \"ù\": \"u\",\n",
        "    \"û\": \"u\",\n",
        "    \"ü\": \"u\",\n",
        "    # Camma (will be replace by dots for floating point numbers)\n",
        "    \",\": \".\",\n",
        "    # And (will be replace by dots for floating point numbers)\n",
        "    \"&\": \" and \",\n",
        "    # Vowels (will be removed)\n",
        "    \"ّ\": \"\",  # tashdid\n",
        "    \"َ\": \"\",  # a\n",
        "    \"ِ\": \"\",  # e\n",
        "    \"ُ\": \"\",  # o\n",
        "    \"ـ\": \"\",  # tatvil\n",
        "    # Spaces\n",
        "    \"‍\": \"\",  # 0x9E -> ZERO WIDTH JOINER\n",
        "    \"‌\": \" \",  # 0x9D -> ZERO WIDTH NON-JOINER\n",
        "    # Arabic Presentation Forms-A (will be replaced by persian one)\n",
        "    \"ﭐ\": \"ا\",\n",
        "    \"ﭑ\": \"ا\",\n",
        "    \"ﭖ\": \"پ\",\n",
        "    \"ﭗ\": \"پ\",\n",
        "    \"ﭘ\": \"پ\",\n",
        "    \"ﭙ\": \"پ\",\n",
        "    \"ﭞ\": \"ت\",\n",
        "    \"ﭟ\": \"ت\",\n",
        "    \"ﭠ\": \"ت\",\n",
        "    \"ﭡ\": \"ت\",\n",
        "    \"ﭺ\": \"چ\",\n",
        "    \"ﭻ\": \"چ\",\n",
        "    \"ﭼ\": \"چ\",\n",
        "    \"ﭽ\": \"چ\",\n",
        "    \"ﮊ\": \"ژ\",\n",
        "    \"ﮋ\": \"ژ\",\n",
        "    \"ﮎ\": \"ک\",\n",
        "    \"ﮏ\": \"ک\",\n",
        "    \"ﮐ\": \"ک\",\n",
        "    \"ﮑ\": \"ک\",\n",
        "    \"ﮒ\": \"گ\",\n",
        "    \"ﮓ\": \"گ\",\n",
        "    \"ﮔ\": \"گ\",\n",
        "    \"ﮕ\": \"گ\",\n",
        "    \"ﮤ\": \"ه\",\n",
        "    \"ﮥ\": \"ه\",\n",
        "    \"ﮦ\": \"ه\",\n",
        "    \"ﮪ\": \"ه\",\n",
        "    \"ﮫ\": \"ه\",\n",
        "    \"ﮬ\": \"ه\",\n",
        "    \"ﮭ\": \"ه\",\n",
        "    \"ﮮ\": \"ی\",\n",
        "    \"ﮯ\": \"ی\",\n",
        "    \"ﮰ\": \"ی\",\n",
        "    \"ﮱ\": \"ی\",\n",
        "    \"ﯼ\": \"ی\",\n",
        "    \"ﯽ\": \"ی\",\n",
        "    \"ﯾ\": \"ی\",\n",
        "    \"ﯿ\": \"ی\",\n",
        "    # Arabic Presentation Forms-B (will be removed)\n",
        "    \"ﹰ\": \"\",\n",
        "    \"ﹱ\": \"\",\n",
        "    \"ﹲ\": \"\",\n",
        "    \"ﹳ\": \"\",\n",
        "    \"ﹴ\": \"\",\n",
        "    \"﹵\": \"\",\n",
        "    \"ﹶ\": \"\",\n",
        "    \"ﹷ\": \"\",\n",
        "    \"ﹸ\": \"\",\n",
        "    \"ﹹ\": \"\",\n",
        "    \"ﹺ\": \"\",\n",
        "    \"ﹻ\": \"\",\n",
        "    \"ﹼ\": \"\",\n",
        "    \"ﹽ\": \"\",\n",
        "    \"ﹾ\": \"\",\n",
        "    \"ﹿ\": \"\",\n",
        "    # Arabic Presentation Forms-B (will be replaced by persian one)\n",
        "    \"ﺀ\": \"ی\",\n",
        "    \"ﺁ\": \"ا\",\n",
        "    \"ﺂ\": \"ا\",\n",
        "    \"ﺃ\": \"ا\",\n",
        "    \"ﺄ\": \"ا\",\n",
        "    \"ﺅ\": \"و\",\n",
        "    \"ﺆ\": \"و\",\n",
        "    \"ﺇ\": \"ا\",\n",
        "    \"ﺈ\": \"ا\",\n",
        "    \"ﺉ\": \"ی\",\n",
        "    \"ﺊ\": \"ی\",\n",
        "    \"ﺋ\": \"ی\",\n",
        "    \"ﺌ\": \"ی\",\n",
        "    \"ﺍ\": \"ا\",\n",
        "    \"ﺎ\": \"ا\",\n",
        "    \"ﺏ\": \"ب\",\n",
        "    \"ﺐ\": \"ب\",\n",
        "    \"ﺑ\": \"ب\",\n",
        "    \"ﺒ\": \"ب\",\n",
        "    \"ﺓ\": \"ه\",\n",
        "    \"ﺔ\": \"ه\",\n",
        "    \"ﺕ\": \"ت\",\n",
        "    \"ﺖ\": \"ت\",\n",
        "    \"ﺗ\": \"ت\",\n",
        "    \"ﺘ\": \"ت\",\n",
        "    \"ﺙ\": \"ث\",\n",
        "    \"ﺚ\": \"ث\",\n",
        "    \"ﺛ\": \"ث\",\n",
        "    \"ﺜ\": \"ث\",\n",
        "    \"ﺝ\": \"ج\",\n",
        "    \"ﺞ\": \"ج\",\n",
        "    \"ﺟ\": \"ج\",\n",
        "    \"ﺠ\": \"ج\",\n",
        "    \"ﺡ\": \"ح\",\n",
        "    \"ﺢ\": \"ح\",\n",
        "    \"ﺣ\": \"ح\",\n",
        "    \"ﺤ\": \"ح\",\n",
        "    \"ﺥ\": \"خ\",\n",
        "    \"ﺦ\": \"خ\",\n",
        "    \"ﺧ\": \"خ\",\n",
        "    \"ﺨ\": \"خ\",\n",
        "    \"ﺩ\": \"د\",\n",
        "    \"ﺪ\": \"د\",\n",
        "    \"ﺫ\": \"ذ\",\n",
        "    \"ﺬ\": \"ذ\",\n",
        "    \"ﺭ\": \"ر\",\n",
        "    \"ﺮ\": \"ر\",\n",
        "    \"ﺯ\": \"ز\",\n",
        "    \"ﺰ\": \"ز\",\n",
        "    \"ﺱ\": \"س\",\n",
        "    \"ﺲ\": \"س\",\n",
        "    \"ﺳ\": \"س\",\n",
        "    \"ﺴ\": \"س\",\n",
        "    \"ﺵ\": \"ش\",\n",
        "    \"ﺶ\": \"ش\",\n",
        "    \"ﺷ\": \"ش\",\n",
        "    \"ﺸ\": \"ش\",\n",
        "    \"ﺹ\": \"ص\",\n",
        "    \"ﺺ\": \"ص\",\n",
        "    \"ﺻ\": \"ص\",\n",
        "    \"ﺼ\": \"ص\",\n",
        "    \"ﺽ\": \"ض\",\n",
        "    \"ﺾ\": \"ض\",\n",
        "    \"ﺿ\": \"ض\",\n",
        "    \"ﻀ\": \"ض\",\n",
        "    \"ﻁ\": \"ط\",\n",
        "    \"ﻂ\": \"ط\",\n",
        "    \"ﻃ\": \"ط\",\n",
        "    \"ﻄ\": \"ط\",\n",
        "    \"ﻅ\": \"ظ\",\n",
        "    \"ﻆ\": \"ظ\",\n",
        "    \"ﻇ\": \"ظ\",\n",
        "    \"ﻈ\": \"ظ\",\n",
        "    \"ﻉ\": \"ع\",\n",
        "    \"ﻊ\": \"ع\",\n",
        "    \"ﻋ\": \"ع\",\n",
        "    \"ﻌ\": \"ع\",\n",
        "    \"ﻍ\": \"غ\",\n",
        "    \"ﻎ\": \"غ\",\n",
        "    \"ﻏ\": \"غ\",\n",
        "    \"ﻐ\": \"غ\",\n",
        "    \"ﻑ\": \"ف\",\n",
        "    \"ﻒ\": \"ف\",\n",
        "    \"ﻓ\": \"ف\",\n",
        "    \"ﻔ\": \"ف\",\n",
        "    \"ﻕ\": \"ق\",\n",
        "    \"ﻖ\": \"ق\",\n",
        "    \"ﻗ\": \"ق\",\n",
        "    \"ﻘ\": \"ق\",\n",
        "    \"ﻙ\": \"ک\",\n",
        "    \"ﻚ\": \"ک\",\n",
        "    \"ﻛ\": \"ک\",\n",
        "    \"ﻜ\": \"ک\",\n",
        "    \"ﻝ\": \"ل\",\n",
        "    \"ﻞ\": \"ل\",\n",
        "    \"ﻟ\": \"ل\",\n",
        "    \"ﻠ\": \"ل\",\n",
        "    \"ﻡ\": \"م\",\n",
        "    \"ﻢ\": \"م\",\n",
        "    \"ﻣ\": \"م\",\n",
        "    \"ﻤ\": \"م\",\n",
        "    \"ﻥ\": \"ن\",\n",
        "    \"ﻦ\": \"ن\",\n",
        "    \"ﻧ\": \"ن\",\n",
        "    \"ﻨ\": \"ن\",\n",
        "    \"ﻩ\": \"ه\",\n",
        "    \"ﻪ\": \"ه\",\n",
        "    \"ﻫ\": \"ه\",\n",
        "    \"ﻬ\": \"ه\",\n",
        "    \"ﻭ\": \"و\",\n",
        "    \"ﻮ\": \"و\",\n",
        "    \"ﻯ\": \"ی\",\n",
        "    \"ﻰ\": \"ی\",\n",
        "    \"ﻱ\": \"ی\",\n",
        "    \"ﻲ\": \"ی\",\n",
        "    \"ﻳ\": \"ی\",\n",
        "    \"ﻴ\": \"ی\",\n",
        "    \"ﻵ\": \"لا\",\n",
        "    \"ﻶ\": \"لا\",\n",
        "    \"ﻷ\": \"لا\",\n",
        "    \"ﻸ\": \"لا\",\n",
        "    \"ﻹ\": \"لا\",\n",
        "    \"ﻺ\": \"لا\",\n",
        "    \"ﻻ\": \"لا\",\n",
        "    \"ﻼ\": \"لا\",\n",
        "}\n",
        "\n",
        "valid_chars = [\n",
        "    \" \",\n",
        "    \"0\",\n",
        "    \"1\",\n",
        "    \"2\",\n",
        "    \"3\",\n",
        "    \"4\",\n",
        "    \"5\",\n",
        "    \"6\",\n",
        "    \"7\",\n",
        "    \"8\",\n",
        "    \"9\",\n",
        "    \"A\",\n",
        "    \"B\",\n",
        "    \"C\",\n",
        "    \"D\",\n",
        "    \"E\",\n",
        "    \"F\",\n",
        "    \"G\",\n",
        "    \"H\",\n",
        "    \"I\",\n",
        "    \"J\",\n",
        "    \"K\",\n",
        "    \"L\",\n",
        "    \"M\",\n",
        "    \"N\",\n",
        "    \"O\",\n",
        "    \"P\",\n",
        "    \"Q\",\n",
        "    \"R\",\n",
        "    \"S\",\n",
        "    \"T\",\n",
        "    \"U\",\n",
        "    \"V\",\n",
        "    \"W\",\n",
        "    \"X\",\n",
        "    \"Y\",\n",
        "    \"Z\",\n",
        "    \"a\",\n",
        "    \"b\",\n",
        "    \"c\",\n",
        "    \"d\",\n",
        "    \"e\",\n",
        "    \"f\",\n",
        "    \"g\",\n",
        "    \"h\",\n",
        "    \"i\",\n",
        "    \"j\",\n",
        "    \"k\",\n",
        "    \"l\",\n",
        "    \"m\",\n",
        "    \"n\",\n",
        "    \"o\",\n",
        "    \"p\",\n",
        "    \"q\",\n",
        "    \"r\",\n",
        "    \"s\",\n",
        "    \"t\",\n",
        "    \"u\",\n",
        "    \"v\",\n",
        "    \"w\",\n",
        "    \"x\",\n",
        "    \"y\",\n",
        "    \"z\",\n",
        "    \"آ\",\n",
        "    \"ئ\",\n",
        "    \"ا\",\n",
        "    \"ب\",\n",
        "    \"ت\",\n",
        "    \"ث\",\n",
        "    \"ج\",\n",
        "    \"ح\",\n",
        "    \"خ\",\n",
        "    \"د\",\n",
        "    \"ذ\",\n",
        "    \"ر\",\n",
        "    \"ز\",\n",
        "    \"س\",\n",
        "    \"ش\",\n",
        "    \"ص\",\n",
        "    \"ض\",\n",
        "    \"ط\",\n",
        "    \"ظ\",\n",
        "    \"ع\",\n",
        "    \"غ\",\n",
        "    \"ف\",\n",
        "    \"ق\",\n",
        "    \"ل\",\n",
        "    \"م\",\n",
        "    \"ن\",\n",
        "    \"ه\",\n",
        "    \"و\",\n",
        "    \"پ\",\n",
        "    \"چ\",\n",
        "    \"ژ\",\n",
        "    \"ک\",\n",
        "    \"گ\",\n",
        "    \"ی\",\n",
        "]\n",
        "\n",
        "\n",
        "def _replace_rep(t):\n",
        "    \"Replace repetitions at the character level: ccc -> c\"\n",
        "\n",
        "    def __replace_rep(m):\n",
        "        c, cc = m.groups()\n",
        "        return f\"{c}\"\n",
        "\n",
        "    re_rep = re.compile(r\"(\\S)(\\1{2,})\")\n",
        "    return re_rep.sub(__replace_rep, t)\n",
        "\n",
        "\n",
        "def _replace_wrep(t):\n",
        "    \"Replace word repetitions: word word word -> word\"\n",
        "\n",
        "    def __replace_wrep(m):\n",
        "        c, cc = m.groups()\n",
        "        return f\"{c}\"\n",
        "\n",
        "    re_wrep = re.compile(r\"(\\b\\w+\\W+)(\\1{2,})\")\n",
        "    return re_wrep.sub(__replace_wrep, t)\n",
        "\n",
        "\n",
        "def _normalize_text(x):\n",
        "    \"\"\"normalize a sentence\"\"\"\n",
        "\n",
        "    x = str(x)\n",
        "    x = parsivar_normalizer.normalize(x)  # apply `parsivar` normalizations\n",
        "    x = re.sub(r\"[\\u200c\\r\\n]\", \" \", x)  # remove half space and new line characters\n",
        "    x = x.lower()\n",
        "    x = \"\".join(\n",
        "        [char_mappings[xx] if xx in char_mappings else xx for xx in x]\n",
        "    )  # substitue bad characters with appropriate ones\n",
        "    x = re.sub(\n",
        "        r\"[^{}]\".format(\"\".join(valid_chars)), \" \", x\n",
        "    )  # just keep valid characters and substitue others with space\n",
        "    x = re.sub(r\"[a-z]+\", r\" \\g<0> \", x)  # put space around words and numbers\n",
        "    x = re.sub(r\"[0-9]+\", r\" \\g<0> \", x)  # put space around words and numbers\n",
        "    x = re.sub(r\"\\s+\", \" \", x)  # remove more than one white spaces with space\n",
        "    x = _replace_rep(x)\n",
        "    x = _replace_wrep(x)\n",
        "    return x.strip()\n",
        "\n",
        "\n",
        "def normalize_texts(X, use_tqdm=False):\n",
        "    \"\"\"normalize list of sentences\"\"\"\n",
        "\n",
        "    if use_tqdm:\n",
        "        X = [_normalize_text(x) for x in tqdm(X)]\n",
        "    else:\n",
        "        X = [_normalize_text(x) for x in X]\n",
        "    return X"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CS0_DyKVkfr5"
      },
      "source": [
        "## Prepare text features"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "7azkOJixaQ5n"
      },
      "outputs": [],
      "source": [
        "df_train.createOrReplaceTempView(\"DATA\")\n",
        "\n",
        "udf_text_procceing = udf(lambda x: ''.join(map(str, normalize_texts(x))) ,StringType())"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "paYMa7KpMcHs",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "4c106443-0750-4f85-e7c6-1e76ce725a4f"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[K     |████████████████████████████████| 212.4 MB 73 kB/s \n",
            "\u001b[K     |████████████████████████████████| 198 kB 81.5 MB/s \n",
            "\u001b[?25h  Building wheel for pyspark (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Requirement already satisfied: fasttext in /usr/local/lib/python3.7/dist-packages (0.9.2)\n",
            "Requirement already satisfied: setuptools>=0.7.0 in /usr/local/lib/python3.7/dist-packages (from fasttext) (57.4.0)\n",
            "Requirement already satisfied: pybind11>=2.2 in /usr/local/lib/python3.7/dist-packages (from fasttext) (2.10.0)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.7/dist-packages (from fasttext) (1.21.6)\n",
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Requirement already satisfied: hazm in /usr/local/lib/python3.7/dist-packages (0.7.0)\n",
            "Requirement already satisfied: libwapiti>=0.2.1 in /usr/local/lib/python3.7/dist-packages (from hazm) (0.2.1)\n",
            "Requirement already satisfied: nltk==3.3 in /usr/local/lib/python3.7/dist-packages (from hazm) (3.3)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.7/dist-packages (from nltk==3.3->hazm) (1.15.0)\n"
          ]
        }
      ],
      "source": [
        "! pip install -q pyspark==3.1.2 spark-nlp\n",
        "!pip install fasttext\n",
        "!pip install hazm\n",
        "import fasttext\n",
        "import fasttext.util\n",
        "from sparknlp.pretrained import PretrainedPipeline\n",
        "import sparknlp\n",
        "from pyspark.ml import Pipeline\n",
        "\n",
        "from sparknlp.base import *\n",
        "from sparknlp.annotator import *\n",
        "\n",
        "import parsivar\n",
        "\n",
        "from __future__ import unicode_literals\n",
        "import hazm"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "import json\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.metrics import classification_report, accuracy_score\n",
        "from pyspark.ml import Pipeline\n",
        "from pyspark.sql import SparkSession\n",
        "import pyspark.sql.functions as F\n",
        "from sparknlp.annotator import *\n",
        "from sparknlp.base import *\n",
        "import sparknlp\n",
        "from sparknlp.pretrained import PretrainedPipeline\n",
        "spark = sparknlp.start()"
      ],
      "metadata": {
        "id": "t4_XGPkEmkhl"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "normalizer_pars = parsivar.Normalizer()\n",
        "normalizer_hazm = hazm.Normalizer()"
      ],
      "metadata": {
        "id": "uGEXEmzME_W_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "MODEL_NAME='dependency_typed_conllu'\n",
        "\n",
        "document_assembler = DocumentAssembler() \\\n",
        "  .setInputCol(\"text\") \\\n",
        "  .setOutputCol(\"document\")\n",
        "\n",
        "sentence_detector = SentenceDetector() \\\n",
        "  .setInputCols([\"document\"]) \\\n",
        "  .setOutputCol(\"sentence\")\n",
        "\n",
        "pos = PerceptronModel.pretrained(\"pos_ud_perdt\", \"fa\") \\\n",
        "  .setInputCols([\"document\", \"token\"]) \\\n",
        "  .setOutputCol(\"pos\")\n",
        "\n",
        "pipeline = Pipeline(stages=[\n",
        "  document_assembler,\n",
        "  sentence_detector,\n",
        "  posTagger\n",
        "])\n",
        "\n",
        "example = spark.createDataFrame([['سلام از John Ben Labs! ']], [\"text\"])\n",
        "\n",
        "result = pipeline.fit(example).transform(example)\n",
        "\n"
      ],
      "metadata": {
        "id": "RPVjO_tcl6qP"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "desc = df_train.select(\"description\").toPandas()"
      ],
      "metadata": {
        "id": "Z-0oMZ1B-17o"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "for i in desc.description:\n",
        "  i = normalizer_pars.normalize(i)\n",
        "  i = normalizer_hazm.normalize(i)"
      ],
      "metadata": {
        "id": "z0H53ye5CQzE"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "stop_words = pd.read_csv(\"/content/stopwords.csv\", header=None)\n",
        "stop_words.drop(columns=[1,2,3],inplace=True)"
      ],
      "metadata": {
        "id": "dfvNBtmiDOuo"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "for i in desc.description:\n",
        "  for j in stop_words[0]:\n",
        "    if j in i:\n",
        "      i.replace(j,\"\")"
      ],
      "metadata": {
        "id": "bfUHvkaoIJxP"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "desc.head()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 206
        },
        "id": "bGR350DgHtnH",
        "outputId": "52edeff6-775b-4470-d581-9d664e4f0d5e"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "\n",
              "  <div id=\"df-37f4be60-9a00-4fbf-82e0-e4dc069c9975\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>description</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>بدون رنگ،کم کارکرد</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>اسفند 95\\nبیمه بدنه کلا تخفیف \\nمانیتور 10 این...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>بیمه شخص ثالث،بیمه بدنه،دارای روکش صندلی و کفی...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>■نمایندگی رجبی کد ۵٣٠٧٣٢\\n□فروش نقدی ■ شعبه تو...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>ماشین صفر برج ۹سال ۹۹ سند رهن ایران خودرو</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-37f4be60-9a00-4fbf-82e0-e4dc069c9975')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-37f4be60-9a00-4fbf-82e0-e4dc069c9975 button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-37f4be60-9a00-4fbf-82e0-e4dc069c9975');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ],
            "text/plain": [
              "                                         description\n",
              "0                                 بدون رنگ،کم کارکرد\n",
              "1  اسفند 95\\nبیمه بدنه کلا تخفیف \\nمانیتور 10 این...\n",
              "2  بیمه شخص ثالث،بیمه بدنه،دارای روکش صندلی و کفی...\n",
              "3  ■نمایندگی رجبی کد ۵٣٠٧٣٢\\n□فروش نقدی ■ شعبه تو...\n",
              "4          ماشین صفر برج ۹سال ۹۹ سند رهن ایران خودرو"
            ]
          },
          "metadata": {},
          "execution_count": 75
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "QdqesE9NNwar"
      },
      "outputs": [],
      "source": [
        "spark = sparknlp.start()\n",
        "# fasttext.util.download_model('fa', if_exists='ignore')  # persian\n",
        "# ft = fasttext.load_model('cc.fa.300.bin')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "40c7dcNITr6u"
      },
      "outputs": [],
      "source": [
        "embeddings = WordEmbeddingsModel.pretrained(\"persian_w2v_cc_300d\", \"fa\") \\  \n",
        "        .setInputCols([\"document\", \"token\"]) \\\n",
        "        .setOutputCol(\"embeddings\")\n",
        "nlp_pipeline = Pipeline(stages=[document_assembler, sentence_detector, tokenizer, embeddings])\n",
        "pipeline_model = nlp_pipeline.fit(spark.createDataFrame([[\"\"]]).toDF(\"text\"))\n",
        "result = pipeline_model.transform(spark.createDataFrame([['من یادگیری ماشین را دوست دارم']], [\"text\"]))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "g1iLxNS3_FY2",
        "outputId": "eb90c577-cbd4-4312-e6e9-b966f8014ebb"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "root\n",
            " |-- post_id: string (nullable = true)\n",
            " |-- review_label: integer (nullable = true)\n",
            " |-- body_status: string (nullable = true)\n",
            " |-- brand: string (nullable = true)\n",
            " |-- brand_model: string (nullable = true)\n",
            " |-- category: string (nullable = true)\n",
            " |-- color: string (nullable = true)\n",
            " |-- description: string (nullable = true)\n",
            " |-- document: string (nullable = true)\n",
            " |-- gearbox: string (nullable = true)\n",
            " |-- new_price: integer (nullable = true)\n",
            " |-- post_type: string (nullable = true)\n",
            " |-- selling_type: string (nullable = true)\n",
            " |-- third_party_insurance_deadline: integer (nullable = true)\n",
            " |-- tit le: string (nullable = true)\n",
            " |-- usage: integer (nullable = true)\n",
            " |-- year: string (nullable = true)\n",
            "\n"
          ]
        }
      ],
      "source": [
        "df_train.printSchema()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8HtIyrDGjba6"
      },
      "source": [
        "## Prepare categorical features"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "gq-rNB1VlTGI"
      },
      "outputs": [],
      "source": [
        "df_train = df_train.fillna(\"0\" ,['year'])\n",
        "df_train = df_train.na.fill(0 ,['new_price'])\n",
        "df_train = df_train.na.fill(-1 ,['usage'])\n",
        "\n",
        "df_test = df_train.fillna(\"0\" ,['year'])\n",
        "df_test = df_test.na.fill(0 ,['new_price'])\n",
        "df_test = df_test.na.fill(-1 ,['usage'])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "1MmqnrVslam3"
      },
      "outputs": [],
      "source": [
        "#change year val to number\n",
        "\n",
        "df_train = df_train.withColumn(\"year\", udf_text_procceing(col(\"year\")))\n",
        "df_train = df_train.withColumn(\"year\",col(\"year\").cast(IntegerType()))\n",
        "df_train = df_train.fillna(0 ,['year'])\n",
        "\n",
        "df_test = df_test.withColumn(\"year\", udf_text_procceing(col(\"year\")))\n",
        "df_test = df_test.withColumn(\"year\",col(\"year\").cast(IntegerType()))\n",
        "df_test = df_test.fillna(0 ,['year'])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "hc6s1L4BlfwH"
      },
      "outputs": [],
      "source": [
        "df_train = df_train.drop(\"third_party_insurance_deadline\",\"category\")    #all of this column is null so it's unusable    #category all is light\n",
        "df_test = df_test.drop(\"third_party_insurance_deadline\",\"category\")    #all of this column is null so it's unusable    #category all is light"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "17NDMrNIZCqS"
      },
      "outputs": [],
      "source": [
        "## uncertain will change or use this columns\n",
        "\n",
        "df_train = df_train.drop(\"brand_model\",\"color\",\"description\",\"title\",\"post_type\")\n",
        "df_test = df_test.drop(\"brand_model\",\"color\",\"description\",\"title\",\"post_type\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "fodwM-dYNt6L"
      },
      "outputs": [],
      "source": [
        "target_cols = ['body_status',\"brand\",\"document\",\"selling_type\"]\n",
        "\n",
        "target_numeric_cols =[]\n",
        "for i in target_cols:\n",
        "  target_numeric_cols.append(i+\"_numeric\")\n",
        "  \n",
        "df_train = df_train.fillna('0',target_cols)\n",
        "df_test = df_test.fillna('0',target_cols)\n",
        "\n",
        "indexer = StringIndexer(inputCols=target_cols ,outputCols=target_numeric_cols)\n",
        "\n",
        "df_train = indexer.fit(df_train).transform(df_train)\n",
        "df_test = indexer.fit(df_test).transform(df_test)\n",
        "\n",
        "for column in target_cols:\n",
        "  df_train = df_train.drop(column)\n",
        "  df_test = df_test.drop(column)\n",
        "\n",
        "for column in target_numeric_cols:\n",
        "  df_train = df_train.withColumn(column,col(column).cast(IntegerType()))\n",
        "  df_test = df_test.withColumn(column,col(column).cast(IntegerType()))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "GUWFvecoVLFG"
      },
      "outputs": [],
      "source": [
        "features = df_train.drop(\"post_id\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OK062-BVXQJV"
      },
      "source": [
        "## feature vector"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "zwIgiwFnkPPC"
      },
      "outputs": [],
      "source": [
        "from pyspark.ml import Pipeline, PipelineModel\n",
        "from pyspark.ml.feature import StringIndexer, VectorAssembler\n",
        "from pyspark.ml.linalg import Vectors,VectorUDT\n",
        "\n",
        "from catboost import CatBoostClassifier"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "C56MoqNVVxdR"
      },
      "outputs": [],
      "source": [
        "y = features.select(\"review_label\").toPandas()\n",
        "X = features.drop(\"review_label\").toPandas()\n",
        "cat_features = list(range(0,X.shape[1]))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "q6P5gjsGyWEd"
      },
      "source": [
        "##Train and Test model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "W6-RRMoyVA4w"
      },
      "outputs": [],
      "source": [
        "model = CatBoostClassifier(iterations=150)\n",
        "model.fit(X,y,cat_features=cat_features,verbose=50) "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "qEUGDZL0Rs2q"
      },
      "outputs": [],
      "source": [
        "model.score(X,y)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "FttC1fAol-aR"
      },
      "outputs": [],
      "source": [
        "x_predict = df_test.toPandas()\n",
        "X_predict = x_predict.set_index(\"post_id\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "SQuUeLlAdtr3"
      },
      "outputs": [],
      "source": [
        "prediction = model.predict_proba(X_predict)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "JzbN2-vGW08p"
      },
      "outputs": [],
      "source": [
        "result = []\n",
        "for [T,F] in prediction:\n",
        "  if T<=F :\n",
        "    result.append(0)\n",
        "  else:\n",
        "    result.append(1)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "G7cra4tgWmqe"
      },
      "outputs": [],
      "source": [
        "result = pd.DataFrame(result, columns = ['predictions'])\n",
        "df_result = pd.concat([result, x_predict[\"post_id\"]], axis=1, join=\"inner\").set_index(\"post_id\")\n",
        "df_result.to_csv(\"/content/result.csv\")\n",
        "df_result.head()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "MBL26kkUc09y"
      },
      "outputs": [],
      "source": [
        "# spark.stop()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "HqtZigiu9Bkn"
      },
      "outputs": [],
      "source": [
        "# df_train.createOrReplaceTempView(\"DATA\")\n",
        "# spark.sql(\"SELECT third_party_insurance_deadline FROM Divar where third_party_insurance_deadline IS NOT NULL\").show()\n",
        "\n",
        "### First code about counting null values and second is about see which column that you want ###\n",
        "# df.select([count(when(isnull(c), c)).alias(c) for c in df.columns]).show() \n",
        "# df.select(['third_party_insurance_deadline','usage','review_label','description']).show()  \n",
        "# df.na.fill('',['color']).show()\n",
        "\n",
        "# spark.sql(\"SELECT * FROM DATA where year IS NULl\").show()\n",
        "# df.groupBy(df.brand).count().show()\n",
        "# row = brand.distinct().count()\n",
        "# df_train.summary().show()    //df.info()  in pandas\n",
        "\n",
        "####################################\n",
        "# farsi : \n",
        "#         post_type(optional)) ,   //\n",
        "#         color(text processing) , //none\n",
        "#         year(normaliaze number - 'utils') ,  //Done\n",
        "#         title(text processing) , \n",
        "#         brand() //31 distinct values\n",
        "# eng : \n",
        "#         brand_model  //none\n",
        "# df.show()\n",
        "# df.select(['post_id','review_label','body_status','brand_model','category','document','gearbox','new_price','selling_type','usage',\"year\"]).show() "
      ]
    }
  ],
  "metadata": {
    "colab": {
      "collapsed_sections": [
        "EOc_utCkjSiq"
      ],
      "provenance": [],
      "authorship_tag": "ABX9TyO5zUXo1GH7UQ/xeTrs5A3s",
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}